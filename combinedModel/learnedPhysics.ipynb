{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "regridded_encode = xr.open_dataset(\"data/encoded_dataa_64x32.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "        'divergence',\n",
    "        'vorticity',\n",
    "        'temperature_deviation',\n",
    "        'specific_humidity',\n",
    "        'specific_cloud_ice_water_content',\n",
    "        'specific_cloud_liquid_water_content',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repeats = 5\n",
    "\n",
    "expanded_regridded_encode = regridded_encode.isel(time=slice(0, 5)).copy()\n",
    "expanded_regridded_encode = xr.concat([expanded_regridded_encode] * num_repeats, dim=\"time\")\n",
    "\n",
    "new_time_values = np.arange(25)\n",
    "expanded_regridded_encode = expanded_regridded_encode.assign_coords(time=new_time_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def xarray_to_torch_dict(ds, fill_value=0.0):\n",
    "    return {\n",
    "        var: torch.tensor(\n",
    "            ds[var].fillna(fill_value).values, dtype=torch.float32\n",
    "        )\n",
    "        for var in ds.data_vars\n",
    "    }\n",
    "    \n",
    "    \n",
    "def reshape_tensors_in_dict(tensor_dict):\n",
    "    return {key: tensor.permute(1, 0, 2, 3) for key, tensor in tensor_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "from learnedPhysics import LearnedPhysicsModel\n",
    "from dynamical_core import DynamicalCoreRunner\n",
    "from loss_function import combined_loss\n",
    "import jax\n",
    "\n",
    "def train_model(expanded_regridded_encode, regridded_encode, variables_to_keep,\n",
    "                num_iterations=24, integration_steps=5, loop_iterations=4, lr=1e-3):\n",
    "\n",
    "    model = LearnedPhysicsModel()\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    criterion = MSELoss()\n",
    "\n",
    "    rng_key = jax.random.PRNGKey(42)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        data_lp = expanded_regridded_encode.isel(time=i)\n",
    "\n",
    "        predicted_tendencies = model.forward(data_lp)\n",
    "\n",
    "        predicted_tendencies = predicted_tendencies.view(6, 32, 64, 32)\n",
    "\n",
    "        if (i + 1) % 5 == 0:\n",
    "\n",
    "            runner = DynamicalCoreRunner(regridded_encode,\n",
    "                                            integration_steps=integration_steps,\n",
    "                                            loop_iterations=loop_iterations,\n",
    "                                            time_i=0)\n",
    "            out_state = runner.run()\n",
    "            \n",
    "            data_pred = expanded_regridded_encode.isel(time=slice(i-4, i+1))\n",
    "            \n",
    "            out_state_pred = out_state.drop_vars([var for var in out_state.data_vars if var not in variables_to_keep])\n",
    "            data_pred = data_pred.drop_vars([var for var in data_pred.data_vars if var not in variables_to_keep])\n",
    "            \n",
    "            \"\"\" out_state_pred_tensor = torch.stack(\n",
    "                [torch.tensor(out_state_pred[var].values, dtype=torch.float32)\n",
    "                    for var in out_state_pred.data_vars],\n",
    "                dim=0\n",
    "            )\n",
    "            \n",
    "            \n",
    "            data_pred_tensor = torch.stack(\n",
    "                [torch.tensor(data_pred[var].values, dtype=torch.float32)\n",
    "                    for var in data_pred.data_vars],\n",
    "                dim=0\n",
    "            ) \"\"\"\n",
    "            \n",
    "            out_state_pred_tensor = xarray_to_torch_dict(out_state_pred, fill_value=0.0)\n",
    "            data_pred_tensor = xarray_to_torch_dict(data_pred, fill_value=0.0)\n",
    "            data_pred_tensor = reshape_tensors_in_dict(data_pred_tensor)\t\n",
    "            #return(out_state_pred_tensor, data_pred_tensor)\n",
    "        \n",
    "            target_error = combined_loss(out_state_pred_tensor, data_pred_tensor)\n",
    "            \n",
    "            loss = criterion(predicted_tendencies, target_error)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f\"Itération {i+1}: Loss = {loss.item():.6f}\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension specified as -2 but tensor has no dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_regridded_encode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregridded_encode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 57\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(expanded_regridded_encode, regridded_encode, variables_to_keep, num_iterations, integration_steps, loop_iterations, lr)\u001b[0m\n\u001b[0;32m     54\u001b[0m data_pred_tensor \u001b[38;5;241m=\u001b[39m reshape_tensors_in_dict(data_pred_tensor)\t\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#return(out_state_pred_tensor, data_pred_tensor)\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m target_error \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_state_pred_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_pred_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(predicted_tendencies, target_error)\n\u001b[0;32m     61\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\mayeu\\SynologyDrive\\DossiersMayeul\\Mes Documents\\TSP\\3A\\PFE\\NeuralGCM\\combinedModel\\loss_function.py:143\u001b[0m, in \u001b[0;36mcombined_loss\u001b[1;34m(out_state, data_era5, ltilde)\u001b[0m\n\u001b[0;32m    140\u001b[0m     loss_model_spec \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m spectral_mse(pred_model, true_model, ltilde)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# Perte de biais (calculée sur la représentation \"data\")\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m     loss_bias \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mspectral_bias_mse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mltilde\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Moyennage sur le nombre de variables\u001b[39;00m\n\u001b[0;32m    146\u001b[0m num_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(variables)\n",
      "File \u001b[1;32mc:\\Users\\mayeu\\SynologyDrive\\DossiersMayeul\\Mes Documents\\TSP\\3A\\PFE\\NeuralGCM\\combinedModel\\loss_function.py:84\u001b[0m, in \u001b[0;36mspectral_bias_mse\u001b[1;34m(field_pred, field_true, ltilde)\u001b[0m\n\u001b[0;32m     82\u001b[0m diff_mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(field_pred \u001b[38;5;241m-\u001b[39m field_true) \u001b[38;5;66;03m#, dim=(0, 1)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# On compare ce biais moyen à zéro en termes d'énergie spectrale\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspectral_mse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff_mean\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mltilde\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mayeu\\SynologyDrive\\DossiersMayeul\\Mes Documents\\TSP\\3A\\PFE\\NeuralGCM\\combinedModel\\loss_function.py:69\u001b[0m, in \u001b[0;36mspectral_mse\u001b[1;34m(field_pred, field_true, ltilde)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspectral_mse\u001b[39m(field_pred, field_true, ltilde):\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    Calcule la MSE entre les énergies spectrales de field_pred et field_true.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    field_pred, field_true : tenseurs de forme (..., lat, lon)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     energy_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_spectral_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mltilde\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     energy_true \u001b[38;5;241m=\u001b[39m compute_spectral_energy(field_true, ltilde)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean((energy_pred \u001b[38;5;241m-\u001b[39m energy_true) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mayeu\\SynologyDrive\\DossiersMayeul\\Mes Documents\\TSP\\3A\\PFE\\NeuralGCM\\combinedModel\\loss_function.py:29\u001b[0m, in \u001b[0;36mcompute_spectral_energy\u001b[1;34m(field, ltilde)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mCalcule l'énergie spectrale d'un champ (sur les dimensions horizontales)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03men effectuant une FFT 2D et en binant les coefficients selon leur distance radiale.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mla somme de l'énergie des coefficients correspondants.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Calcul de la FFT 2D sur les deux dernières dimensions (latitude, longitude)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m field_fft \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrfft2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m energy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(field_fft) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# énergie par coefficient\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Dimensions horizontales\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension specified as -2 but tensor has no dimensions"
     ]
    }
   ],
   "source": [
    "train_model(expanded_regridded_encode, regridded_encode, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'divergence', 'vorticity', 'temperature_deviation', 'temperature',\n",
    "    'specific_humidity', 'specific_cloud_ice_water_content', 'specific_cloud_liquid_water_content',\n",
    "    'log_surface_pressure'\n",
    "]\n",
    "out_state_torch = {\n",
    "    var: torch.tensor(np.random.randn(5, 32, 64, 32).astype(np.float32))\n",
    "    for var in variables\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvPFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
